# ğŸŒ AIâ€‘Powered Business Ecosystem  
**A multiâ€‘tenant, agentâ€‘based platform that automates coding, security, marketing, and businessâ€‘development.**  

> The project is split into microâ€‘services that can be run locally, in Kubernetes, or in a SaaSâ€‘style "multiâ€‘tenant" deployment.  
> Each agent is a thin wrapper around an LLM (GPTâ€‘4oâ€‘mini or Llamaâ€‘2â€‘70B).  
> The stack is intentionally containerâ€‘native so that you can ship a single `dockerâ€‘compose.yaml` to a new customer, or build a Helm chart for a managed Kubernetes deployment.  

---

## Table of Contents  

| Section | What it contains |
|---------|------------------|
| [`repo/`](#repo) | Project layout |
| [`dockerâ€‘compose.yaml`](#docker-composeyaml) | Local dev stack |
| [`agents/`](#agents) | Code for each agent |
| [`services/`](#services) | Nonâ€‘agent services (licensing, metrics, auth) |
| [`actions/`](#actions) | Thin wrappers around external APIs (GitLab, Twitter, Salesforce, Slack) |
| [`llm/`](#llm) | LLM client abstraction |
| [`docs/`](#docs) | Architecture, deployment guides, and docs |
| [`README.md`](#readme) | This file (the one you're reading) |

---

## ğŸ“ Repo Layout  

```
aiâ€‘ecosystem/
â”œâ”€â”€ README.md
â”œâ”€â”€ dockerâ€‘compose.yaml
â”œâ”€â”€ api/
â”‚   â”œâ”€â”€ main.py            # FastAPI gateway
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ agents/
â”‚   â”œâ”€â”€ coding_agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”œâ”€â”€ actions.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ security_agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”œâ”€â”€ actions.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ marketing_agent/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ agent.py
â”‚   â”‚   â”œâ”€â”€ actions.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ bizdev_agent/
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ agent.py
â”‚       â”œâ”€â”€ actions.py
â”‚       â””â”€â”€ Dockerfile
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ licensing/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ main.py
â”‚   â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ metrics/
â”‚       â””â”€â”€ (Prometheus scrape config, Grafana dashboards)
â”œâ”€â”€ llm/
â”‚   â”œâ”€â”€ openai_client.py
â”‚   â”œâ”€â”€ local_client.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ actions/
â”‚   â”œâ”€â”€ gitlab.py
â”‚   â”œâ”€â”€ twitter.py
â”‚   â”œâ”€â”€ slack.py
â”‚   â”œâ”€â”€ crm.py
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ architecture.md
â”‚   â”œâ”€â”€ deployment.md
â”‚   â””â”€â”€ developer.md
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml
```

> **Tip:** Each agent lives in its own folder, so you can build it independently (`docker build -t myorg/coding-agent agents/coding_agent`).  

---

## âš™ï¸ Local Development

### Prerequisites  

| Tool | Version | Install |
|------|---------|---------|
| Docker | â‰¥ 24.0 | `brew install docker` |
| Dockerâ€‘Compose | v2.20+ | `brew install docker-compose` |
| Git | â‰¥ 2.30 | `brew install git` |

> If you prefer Kubernetes, the repo contains a Helm chart in `deploy/helm/`.

### 1ï¸âƒ£ Spin up the full stack

```bash
# From the project root
docker compose up -d
```

> *What it starts:*  
> - API Gateway (FastAPI) â€“ port **8000**  
> - Redis & Kafka â€“ used by the Celery orchestrator  
> - Keycloak â€“ OIDC for multiâ€‘tenant auth (port **8080**)  
> - PostgreSQL â€“ stores tenants, usage logs, agent registry  
> - Licensing Service â€“ records token usage  
> - All four agents, each on a separate container

### 2ï¸âƒ£ Configure Keycloak

```bash
# Add a test realm
docker compose exec keycloak bash -c "kcadm.sh create realms -s realm=demo"

# Create a client
docker compose exec keycloak bash -c "kcadm.sh create clients -r demo -s clientId=ecosystem -s 'public-client'=true -s 'standard-flow-enabled'=true"
```

> After this you'll get a client secret that you can store in an `.env` file and pass to the API Gateway.

### 3ï¸âƒ£ Create a test tenant

```bash
# API call (replace TOKEN with a JWT from Keycloak)
curl -X POST http://localhost:8000/api/tenants \
     -H "Authorization: Bearer $TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"name":"demoâ€‘client"}'
```

### 4ï¸âƒ£ Test the **Coding Agent**

```bash
# Create a PR via GitLab or manually trigger the agent
curl -X POST http://localhost:8000/api/coding_agent/consume \
     -H "Authorization: Bearer $TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"repo":"gitlab.com/demo/demo", "branch":"feature/codify"}'
```

> The agent will create an MR with the updated code.

### 5ï¸âƒ£ Test the **Marketing Agent**

```bash
curl -X POST http://localhost:8000/api/marketing_agent/draft \
     -H "Authorization: Bearer $TOKEN" \
     -H "Content-Type: application/json" \
     -d '{"title":"New product launch","body":"We are excited to launch..."}'
```

> A tweet will be posted and a Slack message will be sent to `#marketing`.

### 6ï¸âƒ£ View Metrics

Prometheus automatically scrapes the `/metrics` endpoint on every container.  
Grafana dashboards are in `services/metrics/grafana`.  
Open Grafana: `http://localhost:3000` (user: `admin`, pass: `admin`).

---

## ğŸ”§ Agent Development

### Common patterns  

| File | Purpose |
|------|---------|
| `agent.py` | StateGraph implementation â€“ nodes, edges, LLM calls |
| `actions.py` | Helper functions to talk to external APIs (GitLab, Twitter, Salesforce, Slack).  Each function returns a plain value â€“ keep it stateless. |
| `Dockerfile` | Simple multiâ€‘stage build that installs only the agent's dependencies. |

#### Example: `marketing_agent/agent.py`

```python
from langgraph.graph import StateGraph, START, END
from langchain.schema import HumanMessage
from ..llm.openai_client import llm
from .actions import post_tweet, send_message

class MarketingAgent(StateGraph):
    def __init__(self):
        super().__init__()

        async def generate(state):
            content = state["content"]
            prompt = (
                f"Write a 280â€‘char tweet from a brand voice. "
                f"Title: {content['title']}. "
                f"Body: {content['body']}"
            )
            response = await llm.agenerate([HumanMessage(content=prompt)])
            return {"tweet": response[0].content.strip()}

        async def publish(state):
            tweet = state["tweet"]
            tweet_id = await post_tweet(tweet)
            await send_message("#marketing", f"âœ… Tweet posted: {tweet[:100]}â€¦")
            return {"tweet_id": tweet_id}

        self.add_node("generate", generate)
        self.add_node("publish", publish)
        self.add_edge(START, "generate")
        self.add_edge("generate", "publish")
        self.add_edge("publish", END)

    async def __call__(self, content: dict):
        return await self.run({"content": content})["publish"]
```

> **Tip:** Keep all prompts small (â‰¤ 300 tokens) to stay under the rateâ€‘limit.

### Running a single agent locally

```bash
cd agents/marketing_agent
docker build -t myorg/marketing-agent .
docker run -p 8081:8081 myorg/marketing-agent
```

> The agent now exposes a simple HTTP endpoint (`POST /generate`) that you can hit directly.

---

## ğŸ”’ Security & Compliance

| Layer | Best practice |
|-------|---------------|
| **Auth** | Keycloak with OIDC; JWT scopes per tenant |
| **Data isolation** | Separate DB schema per tenant (PostgreSQL `search_path`) |
| **Secrets** | Vault or AWS Secrets Manager; mount as env vars |
| **Network** | TLS everywhere; Traefik ingress with Let's Encrypt |
| **Audit** | Log every request (API, Celery, agent) with tenant ID |
| **LLM** | If you run an onâ€‘prem LLM, ensure the server is not exposed publicly |
| **GDPR** | Add an optâ€‘in endpoint for marketing; anonymise lead data |

---

## ğŸ“¦ Packaging for Customers

| Option | How |
|--------|-----|
| **Dockerâ€‘Compose bundle** | Ship `dockerâ€‘compose.yaml` + `Dockerfile`s.  Customer pulls, edits credentials, runs `docker compose up -d`. |
| **Helm chart** | `deploy/helm/ai-ecosystem/` â€“ values.yaml lets them set the number of agents, GPU limits, Stripe keys, etc. |
| **SaaS** | Deploy the entire stack to a managed cluster, expose a `tenantâ€‘portal` for users to create tenants, and autoâ€‘spin GPU nodes on demand. |

---

## ğŸ“š Documentation

* `docs/architecture.md` â€“ Full architecture diagram and component description.  
* `docs/deployment.md` â€“ K8s/Helm deployment instructions, scaling, autoscaling.  
* `docs/developer.md` â€“ How to add a new agent, update the LLM, write actions.  

All docs are written in Markdown so you can render them with any static site generator (MkDocs, Hugo, etc.).

---

## ğŸ¤ Contributing

1. Fork the repo.  
2. Create a feature branch.  
3. Add tests (`pytest` for agent logic).  
4. Update the `docs/` folder if you add a new feature.  
5. Open a PR.  

---

## ğŸ“ Get In Touch

* **Email** â€“ dev@aiâ€‘ecosystem.com  
* **Slack** â€“ Join our workspace: `https://ai-ecosystem.slack.com/`  
* **Discord** â€“ `discord.gg/ai-ecosystem`  

Happy building! ğŸš€
